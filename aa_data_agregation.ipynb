{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zbieranie danych ze zdjęć\n",
    "## Importowanie Bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Korzystaj z kamerki komputera / obrabianie zdjęć\n",
    "import mediapipe as mp # Wykorzystaj model do detekcji punktów na twarzy\n",
    "import json # Pracuj z plikami typu json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowywanie programu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh # Przygotuj model do ekstrakcji siatki twarzy  \n",
    "mp_drawing = mp.solutions.drawing_utils # Przygotuj narzędzie do rysowania siatki twarzy na zdjęciu\n",
    "\n",
    "emotions = {1: \"angry\", 2: \"happy\", 3: \"neutral\", 4: \"sad\", 5: \"surprised\"} # Stwórz słownik do prostszego wyszukiwania zdjęć\n",
    "dummy_variables = {\n",
    "    \"angry\":    [True, False, False, False, False],\n",
    "    \"happy\":    [False, True, False, False, False],\n",
    "    \"neutral\":  [False, False, True, False, False],\n",
    "    \"sad\":      [False, False, False, True, False],\n",
    "    \"surprised\": [False, False, False, False, True]\n",
    "} # Stwórz słownik do prostszego oznaczania danych wyjściowych\n",
    "\n",
    "with open(\"aa_inputs.json\") as inputs_file: # Przy użyciu funkcji 'open()' przy użyciu pliku \"imputs.json\"... \n",
    "    inputs = json.load(inputs_file) # ...zaimportuj dane z tego pliku.\n",
    "\n",
    "with open(\"aa_desired_outputs.json\") as desired_outputs_file: # Przy użyciu funkcji 'open()' przy użyciu pliku \"desired_outputs.json\"...\n",
    "    desired_outputs = json.load(desired_outputs_file) # ...zaimportuj dane z tego pliku.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekstrakcja danych ze zdjęć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def func(integer: int):\n",
    "    ########################################################\n",
    "    emotion = emotions[integer] # Sterowanie resztą programu\n",
    "    ########################################################\n",
    "\n",
    "    IMAGE_FILES = [] # Definicja bazowej listy nazw zdjęć\n",
    "    for i in range(70):\n",
    "        IMAGE_FILES.append(emotion + str(i+1) + \".jpg\") # Wypełnienie listy \n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh: # Przy użyciu modelu mediapipe do siatki twarzy...\n",
    "        for idx, file in enumerate(IMAGE_FILES): # Dla każdego ze zdjęć w liście...\n",
    "            image = cv2.imread(file) # Przy użyciu biblioteki cv2 odczytaj zdjęcie pod zmienną 'file'.\n",
    "            results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) # Konwersja bitmapy BGR (używanej przez cv2) do RGB (używanej przez mediapipe).\n",
    "        \n",
    "            face_coordinates = [] # Definicja bazowej listy koordynatów punktów na twarzy\n",
    "            \n",
    "            if not results.multi_face_landmarks: # W przypadku braku wykrycia twarzy program przejdzie do następnego zdjęcia.\n",
    "                continue\n",
    "            \n",
    "            for face in results.multi_face_landmarks: # Szczerze nie wiem po co jest ta pętla, ale na stack overflow pisali, żeby tak zrobić bez podania przyczyny (obstawiam, że to jest w razie wykrycia większej ilości twarzy, ale nie jestem pewny).\n",
    "                for landmark in face.landmark: # Dla każdgo z koordynatów siatki twarzy dopisz do listy 'face_coordinates' wartość tego koordynatu.\n",
    "                    face_coordinates.append(landmark.x)\n",
    "                    face_coordinates.append(landmark.y)\n",
    "                    face_coordinates.append(landmark.z)\n",
    "            \n",
    "            inputs[\"Values\"].append(face_coordinates) # Do obiektu typu json 'wejścia' dopisz koordynaty twarzy.\n",
    "            desired_outputs[\"Values\"].append(dummy_variables[emotion]) # Do obiektu typu json 'oczekiwane wyjścia' dopisz wartości oczekiwanych emocji.\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    func(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"aa_desired_outputs.json\", 'w') as desired_outputs_file: # Przy użyciu funkcji 'open()' przy użyciu pliku \"imputs.json\"... \n",
    "    json.dump(desired_outputs, desired_outputs_file) # ...załaduj dane do tego pliku.\n",
    "\n",
    "with open(\"aa_inputs.json\", 'w') as inputs_file: # Przy użyciu funkcji 'open()' przy użyciu pliku \"imputs.json\"... \n",
    "    json.dump(inputs, inputs_file) # ...załaduj dane do tego pliku."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
